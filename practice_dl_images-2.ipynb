{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"practice_dl_images.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0samovRq4fN5tP2wd3CDX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"At-vE2wZwGq7","executionInfo":{"status":"ok","timestamp":1635930914247,"user_tz":-180,"elapsed":25761,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}}},"source":["import torch\n","import numpy as np\n","from sklearn.metrics import roc_auc_score"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-0YzElsbwY-Z"},"source":["# Практикум 3, DL for images\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-CkwvRXh2h-G"},"source":["## 1. Пример работы со свертками \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ylVOrzTEDGG","executionInfo":{"status":"ok","timestamp":1635931156877,"user_tz":-180,"elapsed":2111,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}},"outputId":"2ee6726a-9a61-4220-f650-1411db689482"},"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision import transforms\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n","\n","training_data = datasets.CIFAR10(\n","    root='data',\n","    train=True, \n","    download=True,\n","    transform=transform\n",")\n","\n","test_data = datasets.CIFAR10(\n","    root='data',\n","    train=False, \n","    download=True,\n","    transform=transform\n",")\n","\n","trainloader = torch.utils.data.DataLoader(training_data, batch_size=128, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"abwVD97jEGn-","executionInfo":{"status":"ok","timestamp":1635931771507,"user_tz":-180,"elapsed":218,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}}},"source":["from torch import nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3, 6, 5)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.conv2 = nn.Conv2d(6, 16, 5)\n","    self.fc1 = nn.Linear(16*5*5, 120)\n","    self.fc2 = nn.Linear(120, 84)\n","    self.fc3 = nn.Linear(84, 10)\n","\n","  def forward(self, x):\n","    x = self.pool(F.relu(self.conv1(x)))\n","    x = self.pool(F.relu(self.conv2(x)))\n","    x = torch.flatten(x, 1)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxaOnGpvEGqW","executionInfo":{"status":"ok","timestamp":1635931779064,"user_tz":-180,"elapsed":249,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}}},"source":["import torch.optim as optim\n","\n","model = CNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-fKF4HP3x8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635932052137,"user_tz":-180,"elapsed":256737,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}},"outputId":"a14c4fab-97af-48ac-b425-4140fc0f08b2"},"source":["for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 100 == 0:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["[1,     1] loss: 0.001\n","[1,   101] loss: 0.115\n","[1,   201] loss: 0.115\n","[1,   301] loss: 0.115\n","[2,     1] loss: 0.001\n","[2,   101] loss: 0.115\n","[2,   201] loss: 0.114\n","[2,   301] loss: 0.114\n","[3,     1] loss: 0.001\n","[3,   101] loss: 0.110\n","[3,   201] loss: 0.107\n","[3,   301] loss: 0.104\n","[4,     1] loss: 0.001\n","[4,   101] loss: 0.100\n","[4,   201] loss: 0.098\n","[4,   301] loss: 0.097\n","[5,     1] loss: 0.001\n","[5,   101] loss: 0.095\n","[5,   201] loss: 0.094\n","[5,   301] loss: 0.093\n","[6,     1] loss: 0.001\n","[6,   101] loss: 0.091\n","[6,   201] loss: 0.090\n","[6,   301] loss: 0.089\n","[7,     1] loss: 0.001\n","[7,   101] loss: 0.087\n","[7,   201] loss: 0.086\n","[7,   301] loss: 0.085\n","[8,     1] loss: 0.001\n","[8,   101] loss: 0.083\n","[8,   201] loss: 0.081\n","[8,   301] loss: 0.081\n","[9,     1] loss: 0.001\n","[9,   101] loss: 0.079\n","[9,   201] loss: 0.080\n","[9,   301] loss: 0.078\n","[10,     1] loss: 0.001\n","[10,   101] loss: 0.078\n","[10,   201] loss: 0.077\n","[10,   301] loss: 0.077\n","Finished Training\n"]}]},{"cell_type":"code","metadata":{"id":"ar6MX5lM3Ppa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635932119807,"user_tz":-180,"elapsed":4175,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}},"outputId":"42e2e5b5-0813-44f1-977d-c48844a08bfa"},"source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","model.eval()\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 44 %\n"]}]},{"cell_type":"code","metadata":{"id":"0prEH1Q1IAFn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635932366388,"user_tz":-180,"elapsed":4407,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}},"outputId":"f9449f9c-6af8-46a4-9a31-73a53302960b"},"source":["# prepare to count predictions for each class\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","correct_pred = {classname: 0 for classname in classes}\n","total_pred = {classname: 0 for classname in classes}\n","\n","# again no gradients needed\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = model(images)\n","        _, predictions = torch.max(outputs, 1)\n","        # collect the correct predictions for each class\n","        for label, prediction in zip(labels, predictions):\n","            if label == prediction:\n","                correct_pred[classes[label]] += 1\n","            total_pred[classes[label]] += 1\n","\n","\n","# print accuracy for each class\n","for classname, correct_count in correct_pred.items():\n","    accuracy = 100 * float(correct_count) / total_pred[classname]\n","    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n","                                                   accuracy))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class plane is: 51.0 %\n","Accuracy for class car   is: 55.0 %\n","Accuracy for class bird  is: 13.8 %\n","Accuracy for class cat   is: 17.2 %\n","Accuracy for class deer  is: 29.1 %\n","Accuracy for class dog   is: 39.7 %\n","Accuracy for class frog  is: 67.7 %\n","Accuracy for class horse is: 58.4 %\n","Accuracy for class ship  is: 52.6 %\n","Accuracy for class truck is: 59.0 %\n"]}]},{"cell_type":"markdown","metadata":{"id":"LUk__4JR-7sE"},"source":["# Задание\n","\n","Написать и обучить нейронную сеть на датасете CIFAR (5 баллов)\n","1. Замените сверточные слои размера 5х5 на два идущих подряд слоя размером 3х3\n","2. Обучите модель на GPU, 20 эпох\n","\n","Решение необходимо прислать в отдельном ноутбуке\n","\n","\n","Дополнительно:\n","1. (2 балла) Подобрать лучшие значения lr и batch_size"]},{"cell_type":"markdown","metadata":{"id":"ZbX6-eKiKSXF"},"source":["## 2. Используем VGG"]},{"cell_type":"code","metadata":{"id":"gdcne3jmKIVn","executionInfo":{"status":"ok","timestamp":1635932309460,"user_tz":-180,"elapsed":1702,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}}},"source":["import torchvision.models as models\n","\n","vgg16 = models.vgg16(pretrained=True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TmemCeDLWMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635932424138,"user_tz":-180,"elapsed":2085,"user":{"displayName":"Elena Kartysheva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02981934999259921969"}},"outputId":"7b896938-b030-4583-abd4-0780e928b595"},"source":["from torchvision import transforms\n","\n","transform = transforms.Compose(\n","    [transforms.Resize((224, 224)),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n","\n","training_data = datasets.CIFAR10(\n","    root=\"data\", # root is the path where the train/test data is stored\n","    train=True, # train specifies training or test dataset\n","    download=True, # download=True downloads the data from the internet if it’s not available at root\n","    transform=transform # transform and target_transform specify the feature and label transformations\n",")\n","\n","test_data = datasets.CIFAR10(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=transform\n",")\n","\n","trainloader = torch.utils.data.DataLoader(training_data, batch_size=128,\n","                                          shuffle=True, num_workers=2)\n","\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=128,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"jUnx7Kq8L5ly"},"source":["# Задание 2 (5 баллов)\n","1. Обучитите на GPU претренированную модель VGG (минимум 10 эпох)\n","2. Протестируйте ее на всех данных и на каждом классе отдельно\n","\n","Дополнительное задание (5 балла):     \n","\n","* Взять какой-нибудь специфичный датасет с картинками\n","* Взять претренированную VGG (или другу модель) и сделать transfer learning на выбранный датасет"]}]}