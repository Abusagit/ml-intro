{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "ITMO_practice_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu_gh_yePsLk"
      },
      "source": [
        "# GAN\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6iDMYbqP6mh"
      },
      "source": [
        "In this notebook we'll create GAN model to generate images with cats.\n",
        "\n",
        "Based on the [TDS post](https://towardsdatascience.com/getting-started-with-gans-using-pytorch-78e7c22a14a5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WugjcRJQKSw"
      },
      "source": [
        "## Plan\n",
        "\n",
        "1. Load data\n",
        "2. Preprocess data\n",
        "3. Create two models - Generator and Discriminator\n",
        "4. Organize loss calculation\n",
        "5. Generate cats!\n",
        "6. Repeat for human faces!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inX4L8j2QGsp"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d4DyRLJb-RbN"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTKv0v7CQau-"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGiDfHFv-qGq"
      },
      "source": [
        "!wget https://www.dropbox.com/s/329oy3cprlvn5vb/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svbwMLmu_hTl"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('archive.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Kw3yjyBc-RbU"
      },
      "source": [
        "DATA_DIR = './cats/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prHayDBWQm1D"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lwq22FRQ6gW"
      },
      "source": [
        "Before training the model images have to be preprocessed:\n",
        "\n",
        "1. The colors should be normalized (all RGB layers)\n",
        "2. Images have to be sampled as batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KM9gXS8_-RbV"
      },
      "source": [
        "# set parameters of the transformed data\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaCJ8ad5VzXd"
      },
      "source": [
        "# As dataset is stored in the directory, we can create dataset\n",
        "# as ImageFolder PyTorch object and set all the transformations here\n",
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose([\n",
        "    tt.ToTensor(),\n",
        "    tt.Normalize(*stats)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pMyVWzl4-RbV"
      },
      "source": [
        "# Create PyTorch DataLoader object to produce batches\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO-kHhIDR8uj"
      },
      "source": [
        "## Visualization functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0f9IYzCw-RbW"
      },
      "source": [
        "# for the nicer images visualization \n",
        "# we make inverse transformation for normalization\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KqrrdGU9-RbW"
      },
      "source": [
        "# functions to plot images\n",
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "def show_batch(dl, nmax=64):\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "37kE1As2-RbW"
      },
      "source": [
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6u1PYTBSYHK"
      },
      "source": [
        "## Create models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZDekCaxTJDe"
      },
      "source": [
        "**Discriminator** - model to classify images as real and generated. \n",
        "\n",
        "*Note*: Start simple. A few convolutions & batch normalization would do, inception/resnet is an overkill. Too smart discriminator hardly can be fooled by a generator, so the training can be overcomplicated.\n",
        "\n",
        "**Generator** - decoder producing images from the vector of normal distribution.\n",
        "\n",
        "*Note*: use ConvTranspose layers as inversion of usual convolutions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_bxAkzkv-RbX"
      },
      "source": [
        "# Utils functions for GPU usage of neural networks\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3khGdDC4-RbX"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HmeU8F9f-RbY"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wvrcggmn-RbY"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FjohIUJE-RbY"
      },
      "source": [
        "discriminator = to_device(discriminator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7VfBh5ZY-RbY"
      },
      "source": [
        "latent_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vL0yq86R-RbY"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l5Hxlf3v-RbZ"
      },
      "source": [
        "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
        "fake_images = generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zy9y6zge-RbZ"
      },
      "source": [
        "generator = to_device(generator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "77LjTRxb-RbZ"
      },
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "    # Clear discriminator gradients\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    # Pass real images through discriminator\n",
        "    real_preds = discriminator(real_images)\n",
        "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "\n",
        "    # Pass fake images through discriminator\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "    fake_preds = discriminator(fake_images)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    # Update discriminator weights\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6_EyigCZ-RbZ"
      },
      "source": [
        "def train_generator(opt_g):\n",
        "    # Clear generator gradients\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # Update generator weights\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uy-6wcam-Rba"
      },
      "source": [
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ymuSVd4J-Rba"
      },
      "source": [
        "def save_samples(index, latent_tensors, show=True):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(denorm(fake_images).cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ktdP7asN-Rba"
      },
      "source": [
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gXMs5La3-Rba"
      },
      "source": [
        "save_samples(0, fixed_latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHKWmQwFfUbI"
      },
      "source": [
        "def fit(epochs, lr, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "    \n",
        "    # Create optimizers\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            # Train discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            # Train generator\n",
        "            loss_g = train_generator(opt_g)\n",
        "            \n",
        "        # Record losses & scores\n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "        \n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    \n",
        "        # Save generated images\n",
        "        save_samples(epoch+start_idx, fixed_latent, show=True)\n",
        "    \n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wYW2ckYz-Rbb"
      },
      "source": [
        "lr = 0.0002\n",
        "epochs = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QGvpQ3ed-Rbb"
      },
      "source": [
        "history = fit(epochs, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LgNld4q--Rbb"
      },
      "source": [
        "losses_g, losses_d, real_scores, fake_scores = history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JFJxCeEY-Rbb"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JJn__qXP-Rbb"
      },
      "source": [
        "Image('./generated/generated-images-0060.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nkgJIi3q-Rbb"
      },
      "source": [
        "vid_fname = 'gans_training.mp4'\n",
        "\n",
        "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\n",
        "files.sort()\n",
        "\n",
        "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jf_3yjzS-Rbb"
      },
      "source": [
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t8q_qT6m-Rbc"
      },
      "source": [
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXWVpVgnXoLM"
      },
      "source": [
        "# TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxgDprhvX2K3"
      },
      "source": [
        "## Improve GAN's behaviour.\n",
        "\n",
        "\n",
        "1. Try to add more Conv-BN blocks in Discriminator\n",
        "2. Try to add Pooling to Discriminator\n",
        "3. Try to add more Conv-BN blocks in Generator\n",
        "4. Increase `latent_size`\n",
        "5. Try use ELU or LeakyReLU\n",
        "\n",
        "For more tips on improving GAN's stability you can check this [source](https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/)\n",
        "\n",
        "Для получения баллов используйте как минимум 2 tips&tricks из статьи. Укажите в комментарии, что именно вы улучшили."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYUHnxHlcLfO"
      },
      "source": [
        "## Generate Fake Faces!\n",
        "\n",
        "\n",
        "1. Add CenterCrop transformation to images and reduce their size\n",
        "2. Use deeper GAN model\n",
        "3. Obtain model that produce reasonably good faces (\"resembling a car crash victim\" or better)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydtV5JUSXpn0"
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNjoDJAtccYK"
      },
      "source": [
        "!tar xvzf tmp.tgz && rm tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9SJ0Nbc47l"
      },
      "source": [
        "DATA_DIR = './lfw-deepfunneled/'\n",
        "image_size = 250\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb8vIagzc_9I"
      },
      "source": [
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose(#YOUR_CODE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}