{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайные леса\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным и сравнить его эффективность с ансамблями из самых популярных библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание. Используйте реализацию дерева из HW3.\n",
    "\n",
    "#### Параметры конструктора\n",
    "`n_estimators` - количество используемых для предсказания деревьев.\n",
    "\n",
    "Остальное - параметры деревьев.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
    "\n",
    "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация Decision Tree из прошлого ДЗ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    criterion_sum = 0\n",
    "    \n",
    "    overall_amount = len(x)\n",
    "    \n",
    "    for class_members_amount in x.value_counts():\n",
    "        prob = class_members_amount / overall_amount\n",
    "        \n",
    "        criterion_sum += prob * (1 - prob)\n",
    "        \n",
    "    return criterion_sum\n",
    "    \n",
    "def entropy(x):\n",
    "    criterion_sum = 0\n",
    "    \n",
    "    overall_amount = len(x)\n",
    "    \n",
    "    for class_members_amount in x.value_counts():\n",
    "        \n",
    "        prob = class_members_amount / overall_amount\n",
    "        \n",
    "        criterion_sum += prob * np.log2(prob)\n",
    "    \n",
    "    return - criterion_sum\n",
    "\n",
    "def gain(left_right, left_y, right_y, criterion, s_total):\n",
    "    \n",
    "    s_node = len(left_right)\n",
    "    \n",
    "    impurity_left = criterion(left_y)\n",
    "    impurity_right = criterion(right_y)\n",
    "    \n",
    "    information_gain = s_node / s_total * criterion(left_right) - len(left_y) / s_total * criterion(left_y) - len(right_y) / s_total * criterion(right_y)\n",
    "    \n",
    "    \n",
    "    split_info = 0\n",
    "    \n",
    "    for unique_feature, count in zip(left_right.value_counts().index, left_right.value_counts()):\n",
    "        split_info -= count / s_node * np.log2(count / s_node)\n",
    "    \n",
    "    gain_ratio = information_gain / split_info\n",
    "    \n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "class DecisionTreeLeaf:\n",
    "    def __init__(self, data, labels, predecessor):\n",
    "        self.y = labels.value_counts().index[0]\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.size = len(self.labels)\n",
    "        self.depth = predecessor.depth + 1\n",
    "        self.predecessor = predecessor\n",
    "        \n",
    "        self.class_probs = None\n",
    "    \n",
    "    def process_leaf_instance(self):\n",
    "        classes_descending_order = self.labels.value_counts().index.tolist()\n",
    "        classes_probabilities = self.labels.value_counts() / self.labels.shape[0]\n",
    "        self.class_probs = dict(zip(classes_descending_order, classes_probabilities))\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, data, labels, predecessor=None, depth=1):\n",
    "        self.split_dim = None\n",
    "        self.split_value = None\n",
    "        \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.predecessor = predecessor\n",
    "        self.depth = predecessor.depth + 1 if predecessor else depth\n",
    "        \n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1):\n",
    "        self.root = None\n",
    "        self.overall_samples_amount = None\n",
    "        \n",
    "        self.max_depth = max_depth or float(\"inf\")\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.criterion = DecisionTreeClassifier.criterias(criterion)\n",
    "    \n",
    "    @classmethod\n",
    "    def criterias(cls, criterion):\n",
    "        CRITERIA = {\"gini\": gini, \"entropy\": entropy}\n",
    "        \n",
    "        return CRITERIA[criterion]\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = DecisionTreeNode(data=X, labels=y) # по умолчанию, так как будем делить дерево\n",
    "        self.overall_samples_amount = len(y)\n",
    "        self.num_of_classes = len(set(y))\n",
    "        \n",
    "        \n",
    "        split_dim, split_value = self.get_most_informative_split(X, y)\n",
    "        \n",
    "        \n",
    "        self.root.split_dim = split_dim\n",
    "        self.root.split_value = split_value\n",
    "        \n",
    "        \n",
    "        self.split_dataframe(self.root, X, y)\n",
    "        \n",
    "        self.split_node(self.root.left)\n",
    "        self.split_node(self.root.right)\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        proba = []\n",
    "        \n",
    "        for _, x_i in X.iterrows():\n",
    "            destination_node = self.walk(self.root, x_i)\n",
    "            \n",
    "            class_probabilities = {class_: destination_node.class_probs.get(class_, 0) for class_ in range(self.num_of_classes)}\n",
    "            \n",
    "            proba.append(class_probabilities)\n",
    "        \n",
    "        return proba\n",
    "            \n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array([max(p.keys(), key=lambda k: p[k]) for p in proba])\n",
    "    \n",
    "    def walk(self, node, x_i):\n",
    "        if isinstance(node, DecisionTreeLeaf):\n",
    "            return node\n",
    "        if x_i[node.split_dim] < node.split_value:\n",
    "            destination = self.walk(node.left, x_i)\n",
    "        else:\n",
    "            destination = self.walk(node.right, x_i)\n",
    "        return destination\n",
    "    \n",
    "    def get_most_informative_split(self, data, labels):\n",
    "        terminal_IG = float(\"-inf\")\n",
    "        terminal_split_value = None\n",
    "        terminal_split_dim = None\n",
    "        for feature in tqdm(data.columns):\n",
    "        #for feature in tqdm(df.columns):\n",
    "            feature_split_value = None\n",
    "            feature_max_IG = float(\"-inf\")\n",
    "            \n",
    "            \n",
    "            for value in data[feature].unique():\n",
    "            #for value in tqdm(data[feature].unique())\n",
    "                left_y = labels[data[feature] < value]\n",
    "                right_y = labels[data[feature] >= value]\n",
    "                \n",
    "                left_labels = len(set(left_y))\n",
    "                right_labels = len(set(right_y))\n",
    "\n",
    "                \n",
    "                IG = gain(labels, left_y, right_y, self.criterion, self.overall_samples_amount)\n",
    "                \n",
    "                if IG > feature_max_IG:\n",
    "                    feature_max_IG = IG\n",
    "                    feature_split_value = value\n",
    "            \n",
    "            if feature_max_IG > terminal_IG:\n",
    "                terminal_IG = feature_max_IG\n",
    "                terminal_split_dim = feature\n",
    "                terminal_split_value = feature_split_value\n",
    "            \n",
    "        return terminal_split_dim, terminal_split_value\n",
    "    \n",
    "    def split_dataframe(self, node, data, labels):\n",
    "        left_indices = data[node.split_dim] < node.split_value\n",
    "        right_indices = data[node.split_dim] >= node.split_value\n",
    "        \n",
    "        left_data = data[left_indices]\n",
    "        right_data = data[right_indices]\n",
    "        \n",
    "        left_y = labels[left_indices]\n",
    "        right_y = labels[right_indices]\n",
    "        \n",
    "        \n",
    "        # условия для установления левого ответвления листом:\n",
    "        if any((len(set(left_y)) == 1, node.depth + 1== self.max_depth)):\n",
    "            left_child = DecisionTreeLeaf(data=left_data, labels=left_y, predecessor=node)\n",
    "        else:\n",
    "            left_child = DecisionTreeNode(data=left_data, labels=left_y, predecessor=node)\n",
    "        \n",
    "        \n",
    "        if any((len(set(right_y)) == 1, node.depth + 1 == self.max_depth)):\n",
    "            right_child = DecisionTreeLeaf(data=right_data, labels=right_y, predecessor=node)\n",
    "        else:\n",
    "            right_child = DecisionTreeNode(data=right_data, labels=right_y, predecessor=node)\n",
    "            \n",
    "        node.right = right_child\n",
    "        node.left = left_child\n",
    "    \n",
    "    def split_node(self, child):\n",
    "        if isinstance(child, DecisionTreeLeaf):\n",
    "            child.process_leaf_instance()\n",
    "        else:\n",
    "            split_dim, split_value = self.get_most_informative_split(child.data, child.labels)\n",
    "            \n",
    "            child.split_dim = split_dim\n",
    "            child.split_value = split_value\n",
    "            \n",
    "            self.split_dataframe(child, child.data, child.labels)\n",
    "            \n",
    "            self.split_node(child.left)\n",
    "            self.split_node(child.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим унаследованный класс Решающего дерева с целью расширения функционала - теперь в каждом узле будет выбираться `max_features` для поиска лучшего сплита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierExtended(DecisionTreeClassifier):\n",
    "    def __init__(self, max_features_amount, criterion=\"gini\", max_depth=None, min_samples_leaf=1):\n",
    "        super().__init__(criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        \n",
    "        self.max_features_amount = max_features_amount\n",
    "        \n",
    "    \n",
    "    def get_features_subset(self, columns):\n",
    "        random_features = np.random.choice(columns, replace=False, size=self.max_features_amount)\n",
    "        \n",
    "        return random_features\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.root = DecisionTreeNode(data=X, labels=y)\n",
    "        self.overall_samples_amount = len(y)\n",
    "        self.num_of_classes = len(set(y))\n",
    "        \n",
    "        random_features = self.get_features_subset(X.columns)\n",
    "\n",
    "        split_dim, split_value = self.get_most_informative_split(X, y, random_features)\n",
    "        \n",
    "        \n",
    "        self.root.split_dim = split_dim\n",
    "        self.root.split_value = split_value\n",
    "        \n",
    "        \n",
    "        self.split_dataframe(self.root, X, y)\n",
    "        \n",
    "        self.split_node(self.root.left)\n",
    "        self.split_node(self.root.right)\n",
    "    \n",
    "    def get_most_informative_split(self, data, labels, features_subset):\n",
    "        terminal_IG = float(\"-inf\")\n",
    "        terminal_split_value = None\n",
    "        terminal_split_dim = None\n",
    "        \n",
    "        for feature in features_subset:\n",
    "            feature_split_value = None\n",
    "            feature_max_IG = float(\"-inf\")\n",
    "            \n",
    "            \n",
    "            for value in data[feature].unique():\n",
    "                left_y = labels[data[feature] < value]\n",
    "                right_y = labels[data[feature] >= value]\n",
    "                \n",
    "                left_labels = len(set(left_y))\n",
    "                right_labels = len(set(right_y))\n",
    "                                \n",
    "                IG = gain(labels, left_y, right_y, self.criterion, self.overall_samples_amount)\n",
    "                if IG > feature_max_IG and all((len(left_y) >= self.min_samples_leaf, len(right_y >= self.min_samples_leaf))):\n",
    "                    feature_max_IG = IG\n",
    "                    feature_split_value = value\n",
    "            \n",
    "            if feature_max_IG > terminal_IG:\n",
    "                terminal_IG = feature_max_IG\n",
    "                terminal_split_dim = feature\n",
    "                terminal_split_value = feature_split_value\n",
    "\n",
    "        return terminal_split_dim, terminal_split_value\n",
    "    \n",
    "    def split_node(self, child):\n",
    "        if isinstance(child, DecisionTreeLeaf):\n",
    "            child.process_leaf_instance()\n",
    "        else:\n",
    "            split_dim = None\n",
    "            \n",
    "            while split_dim is None:\n",
    "                random_features = self.get_features_subset(child.data.columns)\n",
    "                split_dim, split_value = self.get_most_informative_split(child.data, child.labels,\n",
    "                                                                    random_features)\n",
    "            \n",
    "            child.split_dim = split_dim\n",
    "            child.split_value = split_value\n",
    "            \n",
    "            self.split_dataframe(child, child.data, child.labels)\n",
    "\n",
    "            self.split_node(child.left)\n",
    "            self.split_node(child.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier(BaseEstimator):\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", \n",
    "                 n_estimators=10, bootstrap_ratio=0.8):\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth if max_depth else 999\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap_ratio = 0.8\n",
    "    \n",
    "    @classmethod\n",
    "    def max_features_func(cls, strategy):\n",
    "        \n",
    "        strategies = {\"auto\": np.sqrt,\n",
    "                     \"sqrt\": np.sqrt,\n",
    "                     \"log2\": np.log2,\n",
    "                     }\n",
    "        \n",
    "        return strategies[strategy]\n",
    "        \n",
    "    def bootstrap(self, length):\n",
    "        indices = tuple(np.arange(length))\n",
    "        bootstrap_size = int(length * self.bootstrap_ratio)\n",
    "        bootstrap_indices = np.array([list(np.random.choice(indices, size=bootstrap_size)) for _ in range(self.n_estimators)])\n",
    "        out_of_bag_indices = [list(set(indices) - set(tuple(bootstrap_i))) for bootstrap_i in bootstrap_indices]\n",
    "        \n",
    "        return bootstrap_indices, out_of_bag_indices\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        bootstrap_indices, self.OOB_indices = self.bootstrap(X.shape[0])\n",
    "        max_features_amount = int(self.max_features_func(self.max_features)(X.shape[1]))\n",
    "        self.estimators = np.array([DecisionTreeClassifierExtended(max_depth=self.max_depth,\n",
    "                                                          min_samples_leaf=self.min_samples_leaf,\n",
    "                                                          criterion=self.criterion,\n",
    "                                                                   max_features_amount=max_features_amount) for _ in range(self.n_estimators)])\n",
    "\n",
    "\n",
    "        for estimator_idx in tqdm(range(self.n_estimators)):\n",
    "            X_bootstrapped, y_bootstrapped = X.iloc[bootstrap_indices[estimator_idx]], y.iloc[bootstrap_indices[estimator_idx]]\n",
    "            \n",
    "            \n",
    "            self.estimators[estimator_idx].fit(X_bootstrapped, y_bootstrapped)\n",
    "            \n",
    "            \n",
    "        return self\n",
    "    def get_forest_predictions(self, X):\n",
    "        \n",
    "        return np.array([estimator.predict(X) for estimator in self.estimators]).T\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = self.get_forest_predictions(X)\n",
    "        \n",
    "        forest_final_predictions = np.array([np.argmax(np.bincount(preds)) for preds in predictions])\n",
    "        \n",
    "        return forest_final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "Оптимизируйте по `AUC` на кроссвалидации (размер валидационной выборки - 20%) параметры своей реализации `Random Forest`: \n",
    "\n",
    "максимальную глубину деревьев из [2, 3, 5, 7, 10], количество деревьев из [5, 10, 20, 30, 50, 100]. \n",
    "\n",
    "Постройте `ROC` кривую (и выведите `AUC` и `accuracy`) для лучшего варианта.\n",
    "\n",
    "Подсказка: можно построить сразу 100 деревьев глубины 10, а потом убирать деревья и\n",
    "глубину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x_train = r\"{}x_spam_train.csv\"\n",
    "path_y_train = r\"{}y_spam_train.csv\"\n",
    "path_x_test = r\"{}x_spam_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(path_x_train.format(\"./hw_Ensembles_data/\")).drop(\"Id\", axis=\"columns\")\n",
    "X_test = pd.read_csv(path_x_test.format(\"./hw_Ensembles_data/\"))\n",
    "Id_col = X_test[\"Id\"]\n",
    "\n",
    "X_test.drop(\"Id\", axis=\"columns\", inplace=True)\n",
    "y_train = pd.read_csv(path_y_train.format(\"./hw_Ensembles_data/\")).drop(\"Id\", axis=\"columns\")[\"Expected\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Дискредизируем признаки__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=10, strategy=\"kmeans\", encode=\"ordinal\")\n",
    "\n",
    "X_train_encoded = pd.DataFrame(discretizer.fit_transform(X_train.values), columns=X_train.columns)\n",
    "X_test_encoded = pd.DataFrame(discretizer.transform(X_test.values), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bd13a5f63944348dfad45c71812d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d404ff18294d1d9cad89033c7ea3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebcfdccd46d4084a3a1b3b2ce960e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f977834e8b1b434c960cd4cbccfafb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace1cbd8d10242a88dd9eaa6cc0e86ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m y_tr, y_val \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     15\u001b[0m rfc \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mrfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m pred \u001b[38;5;241m=\u001b[39m rfc\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     20\u001b[0m metric \u001b[38;5;241m=\u001b[39m roc_auc_score(y_true\u001b[38;5;241m=\u001b[39my_val, y_score\u001b[38;5;241m=\u001b[39mpred)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators)):\n\u001b[1;32m     41\u001b[0m     X_bootstrapped, y_bootstrapped \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]], y\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]]\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mestimator_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bootstrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mDecisionTreeClassifierExtended.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_of_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(y))\n\u001b[1;32m     20\u001b[0m random_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_features_subset(X\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m---> 22\u001b[0m split_dim, split_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_most_informative_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39msplit_dim \u001b[38;5;241m=\u001b[39m split_dim\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39msplit_value \u001b[38;5;241m=\u001b[39m split_value\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mDecisionTreeClassifierExtended.get_most_informative_split\u001b[0;34m(self, data, labels, features_subset)\u001b[0m\n\u001b[1;32m     48\u001b[0m left_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(left_y))\n\u001b[1;32m     49\u001b[0m right_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(right_y))\n\u001b[0;32m---> 51\u001b[0m IG \u001b[38;5;241m=\u001b[39m \u001b[43mgain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverall_samples_amount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IG \u001b[38;5;241m>\u001b[39m feature_max_IG \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m((\u001b[38;5;28mlen\u001b[39m(left_y) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, \u001b[38;5;28mlen\u001b[39m(right_y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf))):\n\u001b[1;32m     53\u001b[0m     feature_max_IG \u001b[38;5;241m=\u001b[39m IG\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgain\u001b[0;34m(left_right, left_y, right_y, criterion, s_total)\u001b[0m\n\u001b[1;32m     30\u001b[0m impurity_left \u001b[38;5;241m=\u001b[39m criterion(left_y)\n\u001b[1;32m     31\u001b[0m impurity_right \u001b[38;5;241m=\u001b[39m criterion(right_y)\n\u001b[0;32m---> 33\u001b[0m information_gain \u001b[38;5;241m=\u001b[39m s_node \u001b[38;5;241m/\u001b[39m s_total \u001b[38;5;241m*\u001b[39m criterion(left_right) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(left_y) \u001b[38;5;241m/\u001b[39m s_total \u001b[38;5;241m*\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_y\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(right_y) \u001b[38;5;241m/\u001b[39m s_total \u001b[38;5;241m*\u001b[39m criterion(right_y)\n\u001b[1;32m     36\u001b[0m split_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unique_feature, count \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(left_right\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex, left_right\u001b[38;5;241m.\u001b[39mvalue_counts()):\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgini\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m overall_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_members_amount \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      7\u001b[0m     prob \u001b[38;5;241m=\u001b[39m class_members_amount \u001b[38;5;241m/\u001b[39m overall_amount\n\u001b[1;32m      9\u001b[0m     criterion_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prob \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m prob)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/base.py:1027\u001b[0m, in \u001b[0;36mIndexOpsMixin.value_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_counts\u001b[39m(\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    943\u001b[0m     normalize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m     dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    948\u001b[0m ):\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/algorithms.py:822\u001b[0m, in \u001b[0;36mvalue_counts\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m         keys, counts \u001b[38;5;241m=\u001b[39m value_counts_arraylike(values, dropna)\n\u001b[0;32m--> 822\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort:\n\u001b[1;32m    825\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39mascending)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/series.py:366\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m         data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy, raise_cast_failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 366\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m generic\u001b[38;5;241m.\u001b[39mNDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/internals/managers.py:1582\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleBlockManager\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1579\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mmake_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(block, index)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/internals/blocks.py:2751\u001b[0m, in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m klass \u001b[38;5;129;01mis\u001b[39;00m DatetimeTZBlock \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_datetime64tz_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   2747\u001b[0m     \u001b[38;5;66;03m# TODO: This is no longer hit internally; does it need to be retained\u001b[39;00m\n\u001b[1;32m   2748\u001b[0m     \u001b[38;5;66;03m#  for e.g. pyarrow?\u001b[39;00m\n\u001b[1;32m   2749\u001b[0m     values \u001b[38;5;241m=\u001b[39m DatetimeArray\u001b[38;5;241m.\u001b[39m_simple_new(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m-> 2751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/pandas/core/internals/blocks.py:127\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    124\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_mgr_locs \u001b[38;5;241m=\u001b[39m placement\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, values, placement, ndim: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        1 for SingleBlockManager/Series, 2 for BlockManager/DataFrame\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): ndim will be unnecessary with 2D EAs\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = ParameterGrid({\"max_depth\": [2, 3, 5, 7, 10], \"n_estimators\": [5, 10, 20, 30, 50, 100]})\n",
    "\n",
    "metrics_parameters = {}\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "for parameters in tqdm(param_grid):\n",
    "    metrics = []\n",
    "    for train_index, test_index in kfold.split(X_train_encoded):\n",
    "        X_tr, X_val = X_train_encoded.iloc[train_index], X_train_encoded.iloc[test_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        rfc = RandomForestClassifier(**parameters)\n",
    "        rfc.fit(X_tr, y_tr)\n",
    "        \n",
    "        pred = rfc.predict(X_val)\n",
    "        \n",
    "        metric = roc_auc_score(y_true=y_val, y_score=pred)\n",
    "        metrics.append(metric)\n",
    "    \n",
    "    metrics_parameters[tuple(parameters)] = np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем модель с максимально выигрышными параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_encoded, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m random_forest_final \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrandom_forest_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m random_forest_final\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m bootstrap_indices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOOB_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     33\u001b[0m max_features_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features)(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([DecisionTreeClassifierExtended(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth,\n\u001b[1;32m     35\u001b[0m                                                   min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf,\n\u001b[1;32m     36\u001b[0m                                                   criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion,\n\u001b[1;32m     37\u001b[0m                                                            max_features_amount\u001b[38;5;241m=\u001b[39mmax_features_amount) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators)])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators)):\n\u001b[1;32m     41\u001b[0m     X_bootstrapped, y_bootstrapped \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]], y\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]]\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m bootstrap_indices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOOB_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     33\u001b[0m max_features_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features)(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mDecisionTreeClassifierExtended\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mmax_features_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features_amount\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators)])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators)):\n\u001b[1;32m     41\u001b[0m     X_bootstrapped, y_bootstrapped \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]], y\u001b[38;5;241m.\u001b[39miloc[bootstrap_indices[estimator_idx]]\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mDecisionTreeClassifierExtended.__init__\u001b[0;34m(self, max_features_amount, criterion, max_depth, min_samples_leaf)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_features_amount, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features_amount \u001b[38;5;241m=\u001b[39m max_features_amount\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.__init__\u001b[0;34m(self, criterion, max_depth, min_samples_leaf)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m=\u001b[39m max_depth \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;241m=\u001b[39m min_samples_leaf\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.criterias\u001b[0;34m(cls, criterion)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcriterias\u001b[39m(\u001b[38;5;28mcls\u001b[39m, criterion):\n\u001b[1;32m     90\u001b[0m     CRITERIA \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m: gini, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m: entropy}\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCRITERIA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: Ellipsis"
     ]
    }
   ],
   "source": [
    "random_forest_final = RandomForestClassifier(...)\n",
    "random_forest_final.fit(X_tr, y_tr)\n",
    "pred = random_forest_final.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred):\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    plt.title('ROC curve')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest выглядит так:\n",
    "1. Посчитать out-of-bag ошибку предсказания `err_oob` (https://en.wikipedia.org/wiki/Out-of-bag_error)\n",
    "2. Перемешать значения признака `j` у объектов выборки (у каждого из объектов изменится значение признака `j` на какой-то другой)\n",
    "3. Посчитать out-of-bag ошибку (`err_oob_j`) еще раз.\n",
    "4. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n",
    "\n",
    "Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(rfc, X, labels):    \n",
    "    oob_errors = np.zeros(rfc.n_estimators)\n",
    "    \n",
    "    features_errors = np.zeros(shape=(X.shape[1], rfc.n_estimators))\n",
    "    \n",
    "    \n",
    "    for index, (estimator, oob_indices) in tqdm(enumerate(zip(rfc.estimators, rfc.OOB_indices))):\n",
    "        X_oob = X.iloc[oob_indices]\n",
    "        y_oob_true = labels[oob_indices]\n",
    "\n",
    "        y_oob_predicted = estimator.predict(X_oob)\n",
    "\n",
    "        #print(y_oob_predicted)\n",
    "        #print(y_oob_true.shape, y_oob_predicted.shape)\n",
    "        print(y_oob_predicted.shape, y_oob_true.shape)\n",
    "        oob_error_estimator_i = np.mean(y_oob_predicted == y_oob_true)\n",
    "        #print(\"GGGGG\")\n",
    "        # print(oob_error_estimator_i)\n",
    "        oob_errors[index] = oob_error_estimator_i\n",
    "        #print(\"ASASASASAASASAS\")\n",
    "        # Считаем `err_oob_j`:\n",
    "        for feature_index, feature in enumerate(X.columns):\n",
    "            permutated_features = np.random.permutation(X[feature])\n",
    "            X_permutated_oob = X.copy()\n",
    "            X_permutated_oob[feature] = permutated_features\n",
    "\n",
    "            y_oob_permutated = estimator.predict(X_permutated_oob)\n",
    "            \n",
    "            oob_error_feature_j = np.mean(y_oob_permutated == y_oob_true)\n",
    "            \n",
    "            features_errors[feature_index, index] = oob_error_estimator_i - oob_error_feature_j\n",
    "    \n",
    "    feature_importances = features_errors.mean(0)\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "    \n",
    "def most_important_features(importance, names, k=20):\n",
    "    # Выводит названия k самых важных признаков\n",
    "    idicies = np.argsort(importance)[::-1][:k]\n",
    "    return np.array(names)[idicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте решение на простом синтетическом наборе данных. В результате должна получиться точность `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175327e7c56f4a12b6f340dfd64863da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe73cf95b104d2abd6a974de34227e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447,) (447,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27763/286248466.py:29: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  oob_error_feature_j = np.mean(y_oob_permutated == y_oob_true)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443,) (443,)\n",
      "(462,) (462,)\n",
      "(447,) (447,)\n",
      "(450,) (450,)\n",
      "(451,) (451,)\n",
      "(453,) (453,)\n",
      "(465,) (465,)\n",
      "(459,) (459,)\n",
      "(436,) (436,)\n",
      "(466,) (466,)\n",
      "(442,) (442,)\n",
      "(446,) (446,)\n",
      "(435,) (435,)\n",
      "(439,) (439,)\n",
      "(435,) (435,)\n",
      "(454,) (454,)\n",
      "(449,) (449,)\n",
      "(444,) (444,)\n",
      "(454,) (454,)\n",
      "(455,) (455,)\n",
      "(445,) (445,)\n",
      "(430,) (430,)\n",
      "(440,) (440,)\n",
      "(445,) (445,)\n",
      "(447,) (447,)\n",
      "(446,) (446,)\n",
      "(474,) (474,)\n",
      "(434,) (434,)\n",
      "(447,) (447,)\n",
      "(448,) (448,)\n",
      "(466,) (466,)\n",
      "(444,) (444,)\n",
      "(468,) (468,)\n",
      "(447,) (447,)\n",
      "(441,) (441,)\n",
      "(475,) (475,)\n",
      "(452,) (452,)\n",
      "(459,) (459,)\n",
      "(442,) (442,)\n",
      "(456,) (456,)\n",
      "(449,) (449,)\n",
      "(444,) (444,)\n",
      "(443,) (443,)\n",
      "(451,) (451,)\n",
      "(457,) (457,)\n",
      "(449,) (449,)\n",
      "(453,) (453,)\n",
      "(462,) (462,)\n",
      "(448,) (448,)\n",
      "(452,) (452,)\n",
      "(450,) (450,)\n",
      "(452,) (452,)\n",
      "(438,) (438,)\n",
      "(447,) (447,)\n",
      "(442,) (442,)\n",
      "(456,) (456,)\n",
      "(457,) (457,)\n",
      "(453,) (453,)\n",
      "(434,) (434,)\n",
      "(447,) (447,)\n",
      "(453,) (453,)\n",
      "(456,) (456,)\n",
      "(452,) (452,)\n",
      "(451,) (451,)\n",
      "(449,) (449,)\n",
      "(454,) (454,)\n",
      "(442,) (442,)\n",
      "(437,) (437,)\n",
      "(434,) (434,)\n",
      "(436,) (436,)\n",
      "(446,) (446,)\n",
      "(442,) (442,)\n",
      "(454,) (454,)\n",
      "(458,) (458,)\n",
      "(457,) (457,)\n",
      "(437,) (437,)\n",
      "(440,) (440,)\n",
      "(451,) (451,)\n",
      "(457,) (457,)\n",
      "(459,) (459,)\n",
      "(455,) (455,)\n",
      "(447,) (447,)\n",
      "(437,) (437,)\n",
      "(453,) (453,)\n",
      "(451,) (451,)\n",
      "(437,) (437,)\n",
      "(453,) (453,)\n",
      "(446,) (446,)\n",
      "(449,) (449,)\n",
      "(446,) (446,)\n",
      "(449,) (449,)\n",
      "(445,) (445,)\n",
      "(459,) (459,)\n",
      "(459,) (459,)\n",
      "(446,) (446,)\n",
      "(457,) (457,)\n",
      "(443,) (443,)\n",
      "(452,) (452,)\n",
      "(446,) (446,)\n",
      "Importance: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dataset(size):\n",
    "    X = np.array([(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n",
    "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)])\n",
    "    y = np.array([i % 3 for i in range(size)])\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    return X, y\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y[0])\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X) == y[0].values))\n",
    "print(\"Importance:\", feature_importance(rfc, X, y[0].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте, какие признаки важны для датасета spam? (Используйте файлы x_spam_train и y_spam_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ваш ответ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучите модель на всех данных из x_spam_train и y_spam_train.\n",
    "2. Сделайте submit своего решения и получите значение f1_score не менее 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns = [\"Id\", \"Expected\"])\n",
    "submission[\"Id\"] = test[\"Id\"]\n",
    "submission[\"Expected\"] = #YOUR CODE\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве альтернативы попробуем библиотечные реализации ансамблей моделей. \n",
    "\n",
    "1. [CatBoost](https://catboost.ai/docs/)\n",
    "2. [XGBoost](https://xgboost.readthedocs.io/en/latest/)\n",
    "3. [LightGBM](https://lightgbm.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установите необходимые библиотеки. \n",
    "Возможно, потребуется установка дополнительных пакетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Примените модели для нашего датасета.\n",
    "\n",
    "2. Для стандартного набора параметров у каждой модели нарисуйте `ROC` кривую и выведите `AUC` и `accuracy`.\n",
    "\n",
    "3. Посчитайте время обучения каждой модели (можно использовать [timeit magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)).\n",
    "\n",
    "4. Сравните метрики качества и скорость обучения моделей. Какие выводы можно сделать?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ваш ответ_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
